{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Queue Wait Time\n",
    "\n",
    "### Goal\n",
    "\n",
    "Uses image analysis of in-store video to estimate current wait time for new arrivals.\n",
    "\n",
    "### Set initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure_openai_key:  0c6ea620b69941b48e28c0945c06b43a\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "azure_openai_endpoint='https://mrai.openai.azure.com/'\n",
    "azure_openai_api_version='2024-05-01-preview'\n",
    "azure_openai_chat_deployment='gpt-4o-mini'\n",
    "azure_openai_key = os.environ.get(\"AZURE_OPENAI_KEY\") \n",
    "print('azure_openai_key: ', azure_openai_key)\n",
    "\n",
    "video_path = '../Data/waiting in line.mp4'\n",
    "avgServiceTimeInSec = 30\n",
    "serviceStations = 1\n",
    "videoSamplingInterval = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire video frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1 frames from the video.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_folder, interval):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Check if the video file opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Get the frames per second (fps) of the video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(fps * interval)\n",
    "\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        # Set the position of the next frame to capture\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count * frame_interval)\n",
    "\n",
    "        # Read the next frame\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        # If the frame was not successfully read, we've reached the end of the video\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # Save the frame as an image file\n",
    "        frame_filename = os.path.join(output_folder, f'frame_{frame_count}.jpg')\n",
    "        cv2.imwrite(frame_filename, frame, [cv2.IMWRITE_JPEG_QUALITY, 50])\n",
    "\n",
    "        # Increment the frame count\n",
    "        frame_count += 1\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "    print(f\"Extracted {frame_count} frames from the video.\")\n",
    "\n",
    "output_folder = '../Data/frames'\n",
    "extract_frames(video_path, output_folder, videoSamplingInterval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import base64\n",
    "\n",
    "# from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# openai_credential = DefaultAzureCredential()\n",
    "# token_provider = get_bearer_token_provider(openai_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    #azure_ad_token_provider=azure_openai_key\n",
    ")\n",
    "\n",
    "sysPrompt = f\"\"\"\n",
    "Return number of people in the image. Return a json object with property called count containing number of people in the image\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get people count\n",
    "\n",
    "Call gpt4o-mini to get count of people in a frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Failed to make the request. Error: 400 Client Error: model_error for url: https://mrai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m Failed to make the request. Error: 400 Client Error: model_error for url: https://mrai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrochon\\source\\repos\\videoIndexerSample\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import requests  \n",
    "import base64  \n",
    "from azure.identity import ClientSecretCredential  \n",
    "  \n",
    "# Configuration  \n",
    "TENANT_ID = \"YOUR_TENANT_ID\"  \n",
    "CLIENT_ID = \"YOUR_CLIENT_ID\"  \n",
    "CLIENT_SECRET = \"YOUR_CLIENT_SECRET\"  \n",
    "RESOURCE = \"https://management.azure.com/.default\"  \n",
    "IMAGE_PATH = \"../Data/frames/frame_0.jpg\"\n",
    "  \n",
    "# Authenticate and get token  \n",
    "# credential = ClientSecretCredential(tenant_id=TENANT_ID, client_id=CLIENT_ID, client_secret=CLIENT_SECRET)  \n",
    "# token = credential.get_token(RESOURCE).token  \n",
    "  \n",
    "encoded_image = base64.b64encode(open(IMAGE_PATH, 'rb').read()).decode('ascii')  \n",
    "  \n",
    "headers = {  \n",
    "    \"Content-Type\": \"application/json\",  \n",
    "    #\"Authorization\": f\"Bearer {token}\"  \n",
    "    \"api-key\": azure_openai_key\n",
    "}  \n",
    "  \n",
    "# Payload for the request  \n",
    "payload = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": sysPrompt\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"\\n\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"\\n\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"max_tokens\": 800,\n",
    "  \"response_format\": json_object\n",
    "}  \n",
    "ENDPOINT = \"https://mrai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview\"  \n",
    "  \n",
    "# Send request  \n",
    "try:  \n",
    "    response = requests.post(ENDPOINT, headers=headers, json=payload)  \n",
    "    response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code  \n",
    "except requests.RequestException as e:  \n",
    "    raise SystemExit(f\"Failed to make the request. Error: {e}\")  \n",
    "  \n",
    "print(response.json()[\"choices\"][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 people in the image.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(response.choices[0].message['content'][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='0', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "image_path = \"../Data/frames/frame_0.jpg\"\n",
    "encoded_image = base64.b64encode(open(image_path, 'rb').read()).decode('ascii')  \n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=azure_openai_chat_deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sysPrompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"\\n\"\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                }\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"\\n\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.95,\n",
    "    \"max_tokens\": 800\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
