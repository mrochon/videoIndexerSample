{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use AI Vision\n",
    "\n",
    "[Sample cource](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/vision/azure-ai-vision-imageanalysis/samples/sample_people_image_file.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image analysis results:\n",
      " People:\n",
      "Number of people detected: 8\n",
      " Image height: 720\n",
      " Image width: 1280\n",
      " Model version: 2023-10-01\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------\n",
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n",
    "# ------------------------------------\n",
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "    This sample demonstrates how to detect people in the image file sample.jpg using a synchronous client.\n",
    "\n",
    "    The synchronous (blocking) `analyze` method returns an `ImageAnalysisResult` object.\n",
    "    Its `people` property (a `PeopleResult` object) contains a list of `DetectedPerson` objects.\n",
    "    Each one contains:\n",
    "    - A confidence score in the range [0, 1], with higher values indicating greater confidences in\n",
    "      the detection of a person. \n",
    "    - A `BoundingBox` coordinates in pixels, for a rectangle surrounding the person in the image.\n",
    "\n",
    "USAGE:\n",
    "    python sample_people_image_file.py\n",
    "\n",
    "    Set these two environment variables before running the sample:\n",
    "    1) VISION_ENDPOINT - Your endpoint URL, in the form https://your-resource-name.cognitiveservices.azure.com\n",
    "                         where `your-resource-name` is your unique Azure Computer Vision resource name.\n",
    "    2) VISION_KEY - Your Computer Vision key (a 32-character Hexadecimal number)\n",
    "\"\"\"\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "def sample_people_image_file():\n",
    "    import os\n",
    "    from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "    from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "    # Set the values of your computer vision endpoint and computer vision key\n",
    "    # as environment variables:\n",
    "    try:\n",
    "        endpoint = os.environ[\"VISION_ENDPOINT\"]\n",
    "        key = os.environ[\"VISION_KEY\"]\n",
    "    except KeyError:\n",
    "        print(\"Missing environment variable 'VISION_ENDPOINT' or 'VISION_KEY'\")\n",
    "        print(\"Set them before running this sample.\")\n",
    "        exit()\n",
    "\n",
    "    # Create an Image Analysis client\n",
    "    client = ImageAnalysisClient(\n",
    "        endpoint=endpoint,\n",
    "        credential=AzureKeyCredential(key)\n",
    "    )\n",
    "\n",
    "    # Load image to analyze into a 'bytes' object\n",
    "    with open(\"../Data/frames/frame_0.jpg\", \"rb\") as f:\n",
    "        image_data = f.read()\n",
    "\n",
    "    # Find people in an image stream. This will be a synchronously (blocking) call.\n",
    "    result = client.analyze(\n",
    "        image_data=image_data,\n",
    "        visual_features=[VisualFeatures.PEOPLE]\n",
    "    )\n",
    "\n",
    "    # Print People analysis results to the console\n",
    "    print(\"Image analysis results:\")\n",
    "    print(\" People:\")\n",
    "    peopleCount = 0\n",
    "    if result.people is not None:\n",
    "        for person in result.people.list:\n",
    "            #print(f\"   {person.bounding_box}, Confidence {person.confidence:.4f}\")\n",
    "            if person.confidence > 0.5:\n",
    "                peopleCount += 1\n",
    "\n",
    "    print(f\"Number of people detected: {peopleCount}\")\n",
    "    print(f\" Image height: {result.metadata.height}\")\n",
    "    print(f\" Image width: {result.metadata.width}\")\n",
    "    print(f\" Model version: {result.model_version}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_people_image_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
